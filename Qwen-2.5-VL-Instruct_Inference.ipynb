{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":124686,"databundleVersionId":14664749,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install dependencies\n!pip install -q unsloth transformers qwen-vl-utils","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T20:03:41.441320Z","iopub.execute_input":"2025-11-28T20:03:41.441605Z","iopub.status.idle":"2025-11-28T20:03:45.515778Z","shell.execute_reply.started":"2025-11-28T20:03:41.441583Z","shell.execute_reply":"2025-11-28T20:03:45.514721Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# 1. Load libraries\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom PIL import Image\nfrom unsloth import FastVisionModel\nfrom transformers import AutoProcessor\nfrom qwen_vl_utils import process_vision_info\nfrom sklearn. metrics import f1_score, classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T20:03:45.517890Z","iopub.execute_input":"2025-11-28T20:03:45.518344Z","iopub.status.idle":"2025-11-28T20:03:45.525062Z","shell.execute_reply.started":"2025-11-28T20:03:45.518317Z","shell.execute_reply":"2025-11-28T20:03:45.524366Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# 2. Load Qwen2. 5-VL-7B-Instruct (4-bit NF4 with Unsloth)\nmodel, tokenizer = FastVisionModel.from_pretrained(\n    model_name=\"Qwen/Qwen2.5-VL-7B-Instruct\",\n    load_in_4bit = False,\n    load_in_8bit=True,\n    max_seq_length=2048,\n    device_map=\"auto\",\n)\n\nprocessor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\")\n\nprint(\"✓ Model loaded successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T20:03:45.525900Z","iopub.execute_input":"2025-11-28T20:03:45.526131Z","execution_failed":"2025-11-28T20:04:42.484Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.11.4: Fast Qwen2_5_Vl patching. Transformers: 4.57.2.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.9.0+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post1. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c661f8075d494a4896655d9ea8599dde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21572d6a13db4b6b94c0cb0c112c07f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3937b62877a4e6a8d66fe7b661596ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"154beb92966c41e2be030b209de85b40"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"# Updated binary-classification prompt for meme decoding\nprompt = \"\"\"\nYou are an expert in analyzing memes and determining whether they contain political content.\n\nClassify this meme into ONE of the following two categories:\n\n1. **Political** – The meme targets, references, or implies anything related to:\n   - politicians or political leaders\n   - political parties or ideologies\n   - government policies, elections, movements, activism\n   - political events, national issues, or public administration\n   - political satire, criticism, propaganda, or commentary\n\n2. **NonPolitical** – The meme does NOT contain political intent.  \n   This includes humor, general social topics, personal jokes, pop culture, relationships, gender jokes, daily life, or any content unrelated to politics.\n\nImportant guidelines:\n- Consider both explicit and implicit political meaning.\n- Detect political symbolism, colors, slogans, and indirect references.\n- Ignore OCR noise; focus on the dominant meaning.\n- Sarcasm or indirect jokes still count as Political **if** they relate to politics.\n\nRespond with ONLY ONE word: **Political** or **NonPolitical**.\n\"\"\"\n\nprint(\"Prompt created\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-28T20:04:42.484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Define inference function (CORRECTED)\ndef predict_image(image_path, prompt_text):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"image\", \"image\": image_path},\n                {\"type\": \"text\", \"text\": prompt_text}\n            ]\n        }\n    ]\n    \n    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    \n    image = Image.open(image_path). convert(\"RGB\")\n    \n    # FIXED: process_vision_info returns only 2 values\n    image_inputs, video_inputs = process_vision_info(messages)\n    \n    inputs = processor(\n        text=[text],\n        images=image_inputs,\n        videos=video_inputs,\n        padding=True,\n        return_tensors=\"pt\"\n    ). to(model.device)\n    \n    outputs = model. generate(\n        **inputs,\n        max_new_tokens=50,\n        temperature=0.1\n    )\n    \n    result = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n    \n    # Clean output for binary classification\n    result = result.strip().split()[-1].strip('.,!? \"\\'')\n    \n    # Normalize\n    res = result.lower().strip()\n    \n    # Exact match first\n    if res in [\"political\", \"politics\"]:\n        return \"Political\"\n    elif res in [\"nonpolitical\", \"non-political\", \"not political\", \"not-political\"]:\n        return \"NonPolitical\"","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-28T20:04:42.484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load test CSV\ntest_csv_path = \"/kaggle/input/poli-meme-decode-cuet-cse-fest/PoliMemeDecode/Test/Test.csv\"\ntest_images_dir = \"/kaggle/input/poli-meme-decode-cuet-cse-fest/PoliMemeDecode/Test/Image\"\n\ndf_test = pd.read_csv(test_csv_path)\n# df_test = df_test.head(20)\nprint(f\"Total test samples: {len(df_test)}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-28T20:04:42.484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run predictions on test set\ntest_preds = []\n\nfor _, row in tqdm(df_test. iterrows(), total=len(df_test), desc=\"Predicting test images\"):\n    image_filename = row['Image_name']\n    image_path = os.path.join(test_images_dir, image_filename)\n    \n    if not os.path.exists(image_path):\n        print(f\"Warning: Image not found - {image_path}\")\n        test_preds.append(\"NonPolitical\")\n        continue\n    \n    pred = predict_image(image_path, prompt)\n    test_preds.append(pred)\n\nprint(f\"✓ Test predictions complete!  Processed {len(test_preds)} images\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-28T20:04:42.484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create Test submission file\nsubmission = pd.DataFrame({\n    'Image_name': df_test['Image_name'],\n    'Target': test_preds\n})\n\nsubmission. to_csv('submission.csv', index=False)\nprint(\"✓ Submission file saved to 'submission.csv'\")\nprint(\"\\nFirst 10 predictions:\")\nprint(submission.head(20))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-28T20:04:42.484Z"}},"outputs":[],"execution_count":null}]}